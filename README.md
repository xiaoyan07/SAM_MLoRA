<h2 align="center">Multi-LoRA Fine-Tuned Segment Anything Model for Urban Man-Made Object Extraction</h2>

<h5 align="center"> <a href="https://scholar.google.com/citations?user=MDA37NMAAAAJ&hl=zh-CN">Xiaoyan Lu</a>,
and <a href="https://scholar.google.com/citations?user=SbbCxE8AAAAJ">Qihao Weng</a></h5>


[[`Paper`]()] 


## Multi-LoRA Fine-Tuned SAM Framework

<div align="center">
  <img src="./img/SAM_LoRA.png?raw=true">
</div>

## The training and validation dataset

[<b>DeepGlobe Road Dataset </b>](https://competitions.codalab.org/competitions/18467#participate-get_data)  
[<b>SpaceNet Building Dataset </b>](https://spacenet.ai/spacenet-buildings-dataset-v2/)  

If you have difficulty processing this data, feel free to reach out to me at xiaoyan07.lu@polyu.edu.hk for assistance.


## The validation set spans across five continents.

<div align="center">
  <img src="./img/val_data.png?raw=true">
</div>

[<b>the WHU building (Christchurch) Dataset</b>](http://gpcv.whu.edu.cn/data/building_dataset.html)  
[<b>the other validation Dataset</b>][<b>Baidu Drive</b>]( ), Code:


## Pre-trained model
The pre-trained SAM_MLoRA is released at [<b>Baidu Drive</b>](), Code: 

Feel free to use these code and datasets to develoop your own methods!

## Highlights
The code will be released after the manuscript is accepted.

## License
The owners of the copyright on the data are [The JC STEM Lab of Earth Observations](https://weng-poleis.com/), The Hong Kong Polytechnic University.

<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">
<img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>